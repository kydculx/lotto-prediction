#!/usr/bin/env python3
"""
ğŸ”„ ìë™ ìµœì í™” ë£¨í”„
ì ì¤‘ë¥ ì„ ë°˜ë³µì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ìë™í™” ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os

# ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ìŠ¤ë ˆë”© ë¹„í™œì„±í™” (í”„ë¡œì„¸ìŠ¤ ë³‘ë ¬í™” ì§‘ì¤‘)
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["VECLIB_MAXIMUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"

import json
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from src.data_loader import LottoDataLoader
from src.ensemble_predictor import EnsemblePredictor
from src.optimization_cache import OptimizationCache
import numpy as np
import multiprocessing as mp
from functools import partial
import threading



def worker_eval_cached(args):
    """ìºì‹œëœ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì´ˆê³ ì† í‰ê°€"""
    weights, cached_data = args
    avg_hits, _ = OptimizationCache.evaluate_weights(cached_data, weights)
    return avg_hits, weights


def worker_eval(args):
    """(êµ¬) ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‘ì—…ì í•¨ìˆ˜ wrapper - ë” ì´ìƒ ì‚¬ìš© ì•ˆ í•¨"""
    weights, matrix, test_rounds = args
    avg_hits, _ = run_backtest(matrix, weights, test_rounds, label="parallel")
    return avg_hits, weights


def run_backtest(matrix, weights, test_rounds=50, label=""):
    """ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
    n_draws = len(matrix)
    
    # ë°ì´í„°ë³´ë‹¤ í…ŒìŠ¤íŠ¸ íšŒì°¨ê°€ ë§ìœ¼ë©´ ìµœëŒ€ì¹˜ë¡œ ì¡°ì • (ìµœì†Œ 100íšŒ í•™ìŠµ ë°ì´í„° ë‚¨ê¹€)
    if test_rounds >= n_draws - 100:
        test_rounds = n_draws - 100
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ íšŒì°¨ê°€ ì „ì²´ ë°ì´í„°ë³´ë‹¤ ë§ì•„ {test_rounds}íšŒë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

    hit_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}
    
    for i in range(test_rounds):
        test_idx = n_draws - test_rounds + i
        train_matrix = matrix[:test_idx]
        
        if len(train_matrix) < 100:
            continue
        
        # ì˜ˆì¸¡
        predictor = EnsemblePredictor(train_matrix, weights=weights, use_ml=True, use_validator=True)
        predicted, _ = predictor.predict_single_set()
        
        # ì‹¤ì œ ë²ˆí˜¸
        actual = set(matrix[test_idx])
        
        hits = len(set(predicted) & actual)
        hit_counts[hits] += 1
    
    total = sum(hit_counts.values())
    avg_hits = sum(h * c for h, c in hit_counts.items()) / total if total > 0 else 0
    
    return avg_hits, hit_counts


def mutate_weights(weights, mutation_rate=0.1):
    """ê°€ì¤‘ì¹˜ ëŒì—°ë³€ì´"""
    new_weights = weights.copy()
    
    # ëœë¤ ì—”ì§„ ì„ íƒí•˜ì—¬ ê°€ì¤‘ì¹˜ ì¡°ì •
    engines = list(new_weights.keys())
    
    for _ in range(2):  # 2ê°œ ì—”ì§„ ì¡°ì •
        eng1, eng2 = np.random.choice(engines, size=2, replace=False)
        
        # ê°€ì¤‘ì¹˜ ì´ë™
        delta = np.random.uniform(0.01, mutation_rate)
        
        if new_weights[eng1] > delta:
            new_weights[eng1] -= delta
            new_weights[eng2] += delta
    
    # ì •ê·œí™”
    total = sum(new_weights.values())
    return {k: v / total for k, v in new_weights.items()}


def genetic_optimize(matrix, generations=10, population_size=10, test_rounds=30):
    """ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì í™”"""
    
    # ì´ˆê¸° ê°€ì¤‘ì¹˜
    base_weights = {
        'statistical': 0.18,
        'advanced_pattern': 0.12,
        'sequence_correlation': 0.12,
        'ml': 0.10,           # ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§„ ì¶”ê°€
        'lstm': 0.08,
        'timeseries': 0.08,
        'gap': 0.08,
        'poisson': 0.08,
        'fourier': 0.08,
        'graph': 0.04,
        'pattern': 0.03,
        'numerology': 0.01,    # ìˆ˜ë¹„í•™ ì—”ì§„ ì¶”ê°€
    }
    
    # ì´ˆê¸° ê°œì²´êµ° ìƒì„±
    population = [base_weights.copy()]
    for _ in range(population_size - 1):
        population.append(mutate_weights(base_weights, 0.15))
    
    best_weights = base_weights.copy()
    best_score = 0
    
    print("=" * 60)
    print("ğŸ§¬ ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì‹œì‘")
    print("=" * 60)
    print(f"   ì„¸ëŒ€ ìˆ˜: {generations}")
    print(f"   ê°œì²´êµ° í¬ê¸°: {population_size}")
    print(f"   í…ŒìŠ¤íŠ¸ íšŒì°¨: {test_rounds}")
    print()
    
    # ì½”ì–´ ì„¤ì • (ì‹œìŠ¤í…œ ì—¬ìœ ë¶„ 1ê°œ í™•ë³´)
    num_cores = max(1, mp.cpu_count() - 1)
    
    # âš¡ï¸ ìµœì í™” ìºì‹œ ìƒì„±
    cache = OptimizationCache()
    cached_data = cache.precalculate(matrix, test_rounds)

    for gen in range(generations):
        print(f"ğŸ§¬ ì„¸ëŒ€ {gen+1}/{generations} í‰ê°€ ì¤‘ (CPU ì½”ì–´ {num_cores}ê°œ í™œìš©)")
        
        # ë³‘ë ¬ í‰ê°€ë¥¼ ìœ„í•œ ì¸ì ì¤€ë¹„ (ìºì‹œ ë°ì´í„°)
        task_args = [(w, cached_data) for w in population]
        
        # ìƒíƒœ ê³µìœ  ë³€ìˆ˜
        completed_count = 0
        current_best_in_gen = 0.0
        lock = threading.Lock()
        
        def _progress_monitor():
            start_time = time.time()
            spinner = ['â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡', 'â ']
            idx = 0
            
            while completed_count < population_size:
                elapsed = time.time() - start_time
                percent = completed_count / population_size * 100
                bar_len = 30
                filled = int(bar_len * completed_count / population_size)
                bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
                
                spin = spinner[idx % len(spinner)]
                idx += 1
                
                # ë©”ì¸ ìŠ¤ë ˆë“œì™€ ê°’ ì¶©ëŒ ë°©ì§€
                curr_score = current_best_in_gen
                
                status = f"\r  {spin} [ì‹œê°„: {elapsed:3.0f}s] |{bar}| {percent:5.1f}% ({completed_count}/{population_size}) - ìµœê³ ì ìˆ˜: {curr_score:.4f}"
                sys.stdout.write(status)
                sys.stdout.flush()
                time.sleep(0.1)
                
            # ì™„ë£Œ í›„ ìµœì¢… ì¶œë ¥
            elapsed = time.time() - start_time
            sys.stdout.write(f"\r  âœ… [ì‹œê°„: {elapsed:3.0f}s] |{'â–ˆ'*30}| 100.0% ({population_size}/{population_size}) - ìµœê³ ì ìˆ˜: {current_best_in_gen:.4f}\n")
            sys.stdout.flush()

        # í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„± ë° ì‹¤í–‰
        pool = mp.Pool(processes=num_cores)
        
        # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        monitor_thread = threading.Thread(target=_progress_monitor)
        monitor_thread.start()
        
        try:
            fitness = []
            # imap_unordered ì‚¬ìš©
            for i, res in enumerate(pool.imap_unordered(worker_eval_cached, task_args)):
                score, weights = res
                fitness.append((score, weights))
                
                with lock:
                    completed_count += 1
                    if score > current_best_in_gen:
                        current_best_in_gen = score
            
            monitor_thread.join()
            pool.close()
            pool.join()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            pool.terminate()
            raise
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            pool.terminate()
            raise
        
        # ì •ë ¬
        fitness.sort(key=lambda x: x[0], reverse=True)
        
        # ìµœê³  ê¸°ë¡ ê°±ì‹ 
        if fitness[0][0] > best_score:
            best_score = fitness[0][0]
            best_weights = fitness[0][1].copy()
            print(f"ğŸ¯ ì„¸ëŒ€ {gen+1} ê²°ê³¼: ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜ = {best_score:.4f}")
        else:
            print(f"   ì„¸ëŒ€ {gen+1} ê²°ê³¼: í˜„ì¬ ìµœê³  = {fitness[0][0]:.4f}")
        
        # ìƒìœ„ 50% ì„ íƒ
        survivors = [w for _, w in fitness[:population_size // 2]]
        
        # ìƒˆ ê°œì²´êµ° ìƒì„± (ëŒì—°ë³€ì´)
        new_population = survivors.copy()
        while len(new_population) < population_size:
            parent = survivors[np.random.randint(len(survivors))]
            child = mutate_weights(parent, 0.08)
            new_population.append(child)
        
        population = new_population
    
    print()
    print("=" * 60)
    print(f"âœ… ìµœì í™” ì™„ë£Œ!")
    print(f"   ìµœê³  ì ìˆ˜: {best_score:.4f}")
    print("=" * 60)
    
    return best_weights, best_score


def apply_weights_to_predictor(weights):
    """ìµœì í™”ëœ ê°€ì¤‘ì¹˜ë¥¼ ensemble_predictor.pyì— ì ìš©"""
    predictor_path = Path(__file__).parent / "src" / "ensemble_predictor.py"
    
    with open(predictor_path, 'r') as f:
        content = f.read()
    
    # ê°€ì¤‘ì¹˜ ë¬¸ìì—´ ìƒì„±
    weights_str = "    # ìµœì í™”ëœ ì—”ì§„ ê°€ì¤‘ì¹˜ (ìë™ ìµœì í™”)\n    DEFAULT_WEIGHTS = {\n"
    for name, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):
        weights_str += f"        '{name}': {weight:.4f},\n"
    weights_str += "    }"
    
    # ê¸°ì¡´ ê°€ì¤‘ì¹˜ êµì²´
    import re
    pattern = r"    # ìµœì í™”ëœ ì—”ì§„ ê°€ì¤‘ì¹˜.*?DEFAULT_WEIGHTS = \{[^}]+\}"
    content = re.sub(pattern, weights_str, content, flags=re.DOTALL)
    
    with open(predictor_path, 'w') as f:
        f.write(content)
    
    print(f"âœ… ê°€ì¤‘ì¹˜ê°€ {predictor_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ìë™ ìµœì í™” ë£¨í”„')
    parser.add_argument('--generations', type=int, default=100000, help='ì„¸ëŒ€ ìˆ˜')
    parser.add_argument('--population', type=int, default=12, help='ê°œì²´êµ° í¬ê¸°')
    parser.add_argument('--test-rounds', type=int, default=200, help='í…ŒìŠ¤íŠ¸ íšŒì°¨')
    parser.add_argument('--apply', action='store_true', help='ìµœì í™” ê²°ê³¼ ì ìš©')
    
    args = parser.parse_args()
    
    # ë°ì´í„° ë¡œë“œ
    print("\nâ³ ë°ì´í„° ë¡œë”©...")
    loader = LottoDataLoader()
    loader.load()
    matrix = loader.get_numbers_matrix()
    print(f"âœ… {len(matrix)}íšŒì°¨ ë¡œë“œ ì™„ë£Œ")
    
    # ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”
    best_weights, best_score = genetic_optimize(
        matrix,
        generations=args.generations,
        population_size=args.population,
        test_rounds=args.test_rounds
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š ìµœì í™”ëœ ê°€ì¤‘ì¹˜:")
    for name, weight in sorted(best_weights.items(), key=lambda x: x[1], reverse=True):
        bar = "â–ˆ" * int(weight * 50)
        print(f"  {name:22s}: {weight:.4f} {bar}")
    
    # ìµœì¢… ë°±í…ŒìŠ¤íŒ…
    print("\nğŸ”¬ ìµœì¢… ë°±í…ŒìŠ¤íŒ… (50íšŒì°¨)...")
    final_score, hit_counts = run_backtest(matrix, best_weights, 50)
    
    print("\n   ì ì¤‘ ë¶„í¬:")
    for hits, count in sorted(hit_counts.items(), reverse=True):
        if count > 0:
            pct = count / 50 * 100
            bar = "â–ˆ" * int(pct / 5)
            print(f"   {hits}ê°œ ì ì¤‘: {count:3d}íšŒ ({pct:5.1f}%) {bar}")
    
    print(f"\n   í‰ê·  ì ì¤‘: {final_score:.4f}")
    
    # ê°€ì¤‘ì¹˜ ì ìš©
    if args.apply:
        apply_weights_to_predictor(best_weights)
    else:
        print("\nğŸ’¡ --apply ì˜µì…˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ìë™ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì €ì¥
    result = {
        'best_score': best_score,
        'weights': best_weights,
        'hit_counts': hit_counts
    }
    
    result_path = Path(__file__).parent / "optimization_result.json"
    with open(result_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"\nğŸ“ ê²°ê³¼ê°€ {result_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
