import json
import logging
import sys
import argparse
from pathlib import Path
import numpy as np

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

try:
    from src.data_loader import LottoDataLoader
    from src.ensemble_predictor import EnsemblePredictor
    from src.database_manager import LottoDatabaseManager
except ImportError as e:
    logger.error(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def calculate_frequencies(loader):
    """ë²ˆí˜¸ë³„ ì¶œí˜„ ë¹ˆë„ë¥¼ ê³„ì‚°í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    all_numbers = loader.get_all_numbers_flat()
    unique, counts = np.unique(all_numbers, return_counts=True)
    
    freq_dict = {int(i): 0 for i in range(1, 46)}
    for num, count in zip(unique, counts):
        freq_dict[int(num)] = int(count)
    return freq_dict

def export_results(target_round=None, round_range=None):
    """ë¶„ì„ ì—”ì§„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ JSON ë° SQLiteì— ì €ì¥í•©ë‹ˆë‹¤."""
    
    # 1. ë°ì´í„° ë¡œë“œ ë° DB ë§¤ë‹ˆì € ì´ˆê¸°í™”
    loader = LottoDataLoader()
    loader.check_for_updates()
    db_manager = LottoDatabaseManager()
    
    all_rounds_df = loader.df.copy()
    max_round = int(all_rounds_df['round'].max())
    
    # ì²˜ë¦¬í•  íšŒì°¨ ë¦¬ìŠ¤íŠ¸ ê²°ì •
    targets = []
    if target_round:
        targets = [target_round]
    elif round_range:
        start, end = round_range
        targets = list(range(start, end + 1))
    else:
        # ê¸°ë³¸ê°’: ìµœì‹  íšŒì°¨ ê²°ê³¼ + ëˆ„ë½ëœ ì—­ì‚¬ì  ë°ì´í„° ìë™ ìˆ˜ì§‘
        targets = [None]
        
        # ëˆ„ë½ëœ ì—­ì‚¬ì  JSON íŒŒì¼ í™•ì¸ (íšŒì°¨ 1ë¶€í„° max_round-1ê¹Œì§€)
        history_dir = PROJECT_ROOT / "data" / "history"
        history_dir.mkdir(parents=True, exist_ok=True)
        
        missing_history = []
        for r in range(1, max_round):
            json_file = history_dir / f"prediction_{r+1}.json"
            if not json_file.exists():
                missing_history.append(r)
        
        if missing_history:
            logger.info(f"ğŸ” ëˆ„ë½ëœ ì—­ì‚¬ì  ë°ì´í„° {len(missing_history)}ê°œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            targets = missing_history + targets

    for current_target in targets:
        # 1-1. ë¶„ì„ ëŒ€ìƒ íšŒì°¨ ë° ë‹¤ìŒ íšŒì°¨ ë²ˆí˜¸ ê³„ì‚°
        if current_target:
            target_round_num = current_target
            analysis_round_num = target_round_num # target_round_num ë°ì´í„°ê¹Œì§€ ë³´ê³  target_round_num+1ì„ ì˜ˆì¸¡
        else:
            target_round_num = max_round
            analysis_round_num = target_round_num

        # 1-2. DB í™•ì¸ (ì´ë¯¸ ë¶„ì„ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìµìŠ¤í¬íŠ¸ë§Œ ìˆ˜í–‰)
        existing_data = db_manager.get_prediction(target_round_num)
        
        if existing_data:
            logger.info(f"â­ï¸ {target_round_num}íšŒì°¨ ë°ì´í„°ê°€ DBì— ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìµìŠ¤í¬íŠ¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            prediction_data = existing_data
        else:
            # ì‹ ê·œ ë¶„ì„ ìˆ˜í–‰
            if current_target:
                logger.info(f"ğŸ“ {target_round_num}íšŒì°¨ ì‹œì  ë¶„ì„ ì¤‘...")
                loader.df = all_rounds_df[all_rounds_df['round'] <= target_round_num].copy()
                loader.numbers_df = loader.df[['num1', 'num2', 'num3', 'num4', 'num5', 'num6']].copy()
            else:
                logger.info("ğŸš€ ìµœì‹  íšŒì°¨ ë¶„ì„ ì¤‘...")
                loader.df = all_rounds_df.copy()
                loader.numbers_df = loader.df[['num1', 'num2', 'num3', 'num4', 'num5', 'num6']].copy()

            matrix = loader.get_numbers_matrix()
            if matrix is None or len(matrix) == 0:
                logger.warning(f"{target_round_num}íšŒì°¨: ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê±´ë„ˆëœœ")
                continue

            # 2. AI ì—”ì§„ ë¶„ì„ ì‹¤í–‰
            predictor = EnsemblePredictor(matrix)
            report = predictor.get_detailed_report(n_sets=100)
            
            # 3. ë°ì´í„° êµ¬ì¡°í™”
            prediction_data = {
                'latest_round': target_round_num,
                'next_round': target_round_num + 1,
                'hot_cold': report['hot_cold'],
                'engine_predictions': {k: [int(n) for n in v] for k, v in report['engine_predictions'].items()},
                'predicted_sets': [
                    {'numbers': [int(n) for n in s[0]], 'confidence': float(s[1])}
                    for s in report['predicted_sets']
                ],
                'sum_range': report['sum_range'],
                'export_time': Path(loader.file_path).stat().st_mtime if loader.file_path.exists() else 0
            }
            
            # DB ì €ì¥
            db_manager.save_prediction(target_round_num, prediction_data)
        
        # 4. JSON íŒŒì¼ ìµìŠ¤í¬íŠ¸ (ì •ì  ì‚¬ì´íŠ¸ í˜¸í™˜ìš©)
        is_historical = target_round_num < max_round
        
        if is_historical:
            data_dir = PROJECT_ROOT / "data" / "history"
            prediction_filename = f"prediction_{target_round_num + 1}.json"
        else:
            data_dir = PROJECT_ROOT / "data"
            prediction_filename = "prediction.json"
            
        data_dir.mkdir(parents=True, exist_ok=True)

        # JSON ì €ì¥
        file_path = data_dir / prediction_filename
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(prediction_data, f, ensure_ascii=False, indent=2)
        
        if not is_historical:
            # ìµœì‹  íšŒì°¨ì¼ ë•Œë§Œ stats.jsonê³¼ frequencies.json ì—…ë°ì´íŠ¸ ë° DB ì €ì¥
            stats_data = {
                'total_draws': len(all_rounds_df),
                'latest_draw': [int(n) for n in all_rounds_df.iloc[-1][['num1','num2','num3','num4','num5','num6']].values],
                'rounds': all_rounds_df['round'].tolist()[-50:],
            }
            freq_data = calculate_frequencies(loader)
            
            # íŒŒì¼ ì €ì¥
            with open(data_dir / "stats.json", 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, ensure_ascii=False, indent=2)
            with open(data_dir / "frequencies.json", 'w', encoding='utf-8') as f:
                json.dump(freq_data, f, ensure_ascii=False, indent=2)
                
            # DB ë©”íƒ€ ì €ì¥
            db_manager.save_meta("stats", stats_data)
            db_manager.save_meta("frequencies", freq_data)
            
            logger.info(f"ğŸ’¾ ìµœì‹  ë°ì´í„° ë° í†µê³„ ì €ì¥ ì™„ë£Œ (DB & JSON)")
        else:
            logger.debug(f"ğŸ’¾ ì—­ì‚¬ì  ë°ì´í„° ìµìŠ¤í¬íŠ¸ ì™„ë£Œ: {file_path}")

    logger.info("âœ… ëª¨ë“  ìš”ì²­ëœ ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Lotto AI ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
    parser.add_argument("--round", type=int, help="ë¶„ì„ ì‹œì ìœ¼ë¡œ ì§€ì •í•  íšŒì°¨ (ì˜ˆ: 100)")
    parser.add_argument("--range", type=str, help="ë¶„ì„í•  íšŒì°¨ ë²”ìœ„ (ì˜ˆ: 1-100)")
    args = parser.parse_args()
    
    round_range = None
    if args.range:
        try:
            start, end = map(int, args.range.split('-'))
            round_range = (start, end)
        except ValueError:
            logger.error("ë²”ìœ„ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì˜ˆ: 1-100)")
            sys.exit(1)

    try:
        export_results(target_round=args.round, round_range=round_range)
    except Exception as e:
        logger.exception(f"ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
